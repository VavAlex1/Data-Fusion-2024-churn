{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8031554,"sourceType":"datasetVersion","datasetId":4634103}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optuna\n!pip install lifelines","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:54:23.760230Z","iopub.execute_input":"2024-04-05T19:54:23.760614Z","iopub.status.idle":"2024-04-05T19:54:52.420214Z","shell.execute_reply.started":"2024-04-05T19:54:23.760587Z","shell.execute_reply":"2024-04-05T19:54:52.419136Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.2)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\nCollecting lifelines\n  Downloading lifelines-0.28.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy<2.0,>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.11.4)\nRequirement already satisfied: pandas>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (2.1.4)\nRequirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (3.7.5)\nCollecting autograd>=1.5 (from lifelines)\n  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\nCollecting autograd-gamma>=0.3 (from lifelines)\n  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting formulaic>=0.2.2 (from lifelines)\n  Downloading formulaic-1.0.1-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.10/site-packages (from autograd>=1.5->lifelines) (1.0.0)\nCollecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines) (4.9.0)\nRequirement already satisfied: wrapt>=1.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2.0->lifelines) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2.0->lifelines) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\nDownloading lifelines-0.28.0-py3-none-any.whl (349 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.2/349.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading autograd-1.6.2-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading formulaic-1.0.1-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: autograd-gamma\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=8ba9a8465c655cd976d03bb523b636c3e7ac42244a1d5327f5e359d3bd83e389\n  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\nSuccessfully built autograd-gamma\nInstalling collected packages: interface-meta, autograd, autograd-gamma, formulaic, lifelines\nSuccessfully installed autograd-1.6.2 autograd-gamma-0.5.0 formulaic-1.0.1 interface-meta-1.3.0 lifelines-0.28.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom lifelines.utils import concordance_index\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:54:52.422077Z","iopub.execute_input":"2024-04-05T19:54:52.422409Z","iopub.status.idle":"2024-04-05T19:54:55.030446Z","shell.execute_reply.started":"2024-04-05T19:54:52.422367Z","shell.execute_reply":"2024-04-05T19:54:55.029678Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"clients = pd.read_csv('/kaggle/input/data-fusion-contest-2024-2/clients.csv')\nreport_dates = pd.read_csv('/kaggle/input/data-fusion-contest-2024-2/report_dates.csv', parse_dates=['report_dt'])\ntrain = pd.read_csv('/kaggle/input/data-fusion-contest-2024-2/train.csv')\ntransactions = pd.read_csv('/kaggle/input/data-fusion-contest-2024-2/transactions.csv.zip/transactions.csv', \n                           parse_dates=['transaction_dttm'])","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:54:55.031475Z","iopub.execute_input":"2024-04-05T19:54:55.031838Z","iopub.status.idle":"2024-04-05T19:55:19.195247Z","shell.execute_reply.started":"2024-04-05T19:54:55.031814Z","shell.execute_reply":"2024-04-05T19:55:19.194461Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"clients = clients.merge(report_dates, how='left', on='report')\ntransactions = transactions.sort_values('transaction_dttm').reset_index(drop=True)\ntransactions = transactions.merge(clients, how='left', on='user_id')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:19.197423Z","iopub.execute_input":"2024-04-05T19:55:19.197708Z","iopub.status.idle":"2024-04-05T19:55:24.240670Z","shell.execute_reply.started":"2024-04-05T19:55:19.197683Z","shell.execute_reply":"2024-04-05T19:55:24.239847Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# 1.","metadata":{}},{"cell_type":"code","source":"transactions['trans_positive'] = np.where( transactions['transaction_amt']>0,transactions['transaction_amt'],np.nan)\ntransactions['trans_negative'] = np.where( transactions['transaction_amt']<0,\n                                          np.abs(transactions['transaction_amt']),np.nan)\ntransactions['days_to_report'] = (transactions['report_dt'] - transactions['transaction_dttm']).dt.days","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:24.241699Z","iopub.execute_input":"2024-04-05T19:55:24.241957Z","iopub.status.idle":"2024-04-05T19:55:24.909063Z","shell.execute_reply.started":"2024-04-05T19:55:24.241935Z","shell.execute_reply":"2024-04-05T19:55:24.908055Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"min_day_trans = transactions.groupby(['user_id'])[['days_to_report']].min().\\\n    rename(columns={\"days_to_report\":\"min_day_trans\"}).reset_index()\nmax_day_trans = transactions.groupby(['user_id'])[['days_to_report']].max().\\\n    rename(columns={\"days_to_report\":\"max_day_trans\"}).reset_index()\ncount_trans = transactions.groupby(['user_id'])[['days_to_report']].count().\\\n    rename(columns={\"days_to_report\":\"count_trans\"}).reset_index()\nnunique_days = transactions.groupby('user_id')[['days_to_report']].nunique().\\\n    rename({'days_to_report': 'nunique_days'}, axis=1).reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:24.910319Z","iopub.execute_input":"2024-04-05T19:55:24.910723Z","iopub.status.idle":"2024-04-05T19:55:27.744552Z","shell.execute_reply.started":"2024-04-05T19:55:24.910685Z","shell.execute_reply":"2024-04-05T19:55:27.743743Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 2.","metadata":{}},{"cell_type":"code","source":"transactions = transactions.merge(min_day_trans, how='left', on='user_id')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:27.745789Z","iopub.execute_input":"2024-04-05T19:55:27.746085Z","iopub.status.idle":"2024-04-05T19:55:30.444304Z","shell.execute_reply.started":"2024-04-05T19:55:27.746058Z","shell.execute_reply":"2024-04-05T19:55:30.443287Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"transactions['days_groups'] = 0\ntransactions.loc[transactions['days_to_report']<=transactions['min_day_trans']+10, 'days_groups'] = 10\ntransactions.loc[transactions['days_to_report']<=transactions['min_day_trans']+5, 'days_groups'] = 5\ntransactions.loc[transactions['days_to_report']==transactions['min_day_trans'], 'days_groups'] = 1","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:30.445510Z","iopub.execute_input":"2024-04-05T19:55:30.445807Z","iopub.status.idle":"2024-04-05T19:55:30.609963Z","shell.execute_reply.started":"2024-04-05T19:55:30.445783Z","shell.execute_reply":"2024-04-05T19:55:30.609187Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"trans_days_groups = transactions[~transactions['days_groups'].isin([0])].pivot_table(\n    index = 'user_id',\n    values=['trans_positive', 'trans_negative'],\n    columns=['days_groups'],\n    aggfunc=['count','sum', 'max', 'min']\n)\ntrans_days_groups.columns = [f'days_groups_{x[0]}_{x[1]}_{x[2]}' for x in trans_days_groups.columns]\ntrans_days_groups.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:30.611355Z","iopub.execute_input":"2024-04-05T19:55:30.611743Z","iopub.status.idle":"2024-04-05T19:55:31.633396Z","shell.execute_reply.started":"2024-04-05T19:55:30.611708Z","shell.execute_reply":"2024-04-05T19:55:31.632519Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"trans_cur_groups = transactions.pivot_table(\n    index = 'user_id',\n    values=['trans_positive', 'trans_negative'],\n    columns=['currency_rk'],\n    aggfunc=['count','sum', 'max', 'min']\n)\ntrans_cur_groups.columns = [f'cur_groups_{x[0]}_{x[1]}_{x[2]}' for x in trans_cur_groups.columns]\ntrans_cur_groups.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:31.638102Z","iopub.execute_input":"2024-04-05T19:55:31.638448Z","iopub.status.idle":"2024-04-05T19:55:35.848714Z","shell.execute_reply.started":"2024-04-05T19:55:31.638420Z","shell.execute_reply":"2024-04-05T19:55:35.847584Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 3.","metadata":{}},{"cell_type":"code","source":"mcc_days_groups = transactions[~transactions['days_groups'].isin([0])].pivot_table(\n    index = 'user_id',\n    values=['mcc_code'],\n    columns=['days_groups'],\n    aggfunc=[\"count\",'nunique']\n)\nmcc_days_groups.columns = [f'days_groups_mcc_{x[0]}_{x[1]}_{x[2]}' for x in mcc_days_groups.columns]\nmcc_days_groups.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:35.850072Z","iopub.execute_input":"2024-04-05T19:55:35.850472Z","iopub.status.idle":"2024-04-05T19:55:36.466076Z","shell.execute_reply.started":"2024-04-05T19:55:35.850440Z","shell.execute_reply":"2024-04-05T19:55:36.465016Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"count_mcc_code = transactions.mcc_code.value_counts().to_frame().reset_index()\n\ncount_mcc_code20000 = np.array(count_mcc_code[(count_mcc_code['count']>20000)&\n                                             (count_mcc_code['count']<1000000)].mcc_code)\n\nmcc_code_dumm20000 = pd.get_dummies(transactions[transactions['mcc_code'].isin(count_mcc_code20000)].\\\n                               set_index('user_id')['mcc_code'])\nmcc_code_dumm20000.columns = [f'mcc_count_{x}' for x in mcc_code_dumm20000.columns]\nmcc_code_dumm20000 = mcc_code_dumm20000.groupby(['user_id']).agg('sum').reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:36.467570Z","iopub.execute_input":"2024-04-05T19:55:36.467932Z","iopub.status.idle":"2024-04-05T19:55:41.448568Z","shell.execute_reply.started":"2024-04-05T19:55:36.467899Z","shell.execute_reply":"2024-04-05T19:55:41.447767Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"count_mcc_code = transactions.mcc_code.value_counts().to_frame().reset_index()\n\ncount_mcc_code20000 = np.array(count_mcc_code[(count_mcc_code['count']>20000)&\n                                             (count_mcc_code['count']<1000000)].mcc_code)\n\nmcc_code_dumm20000 = pd.get_dummies(transactions[transactions['mcc_code'].isin(count_mcc_code20000)].\\\n                               set_index('user_id')['mcc_code'])\nmcc_code_dumm20000.columns = [f'mcc_count_{x}' for x in mcc_code_dumm20000.columns]\nmcc_code_dumm20000 = mcc_code_dumm20000.groupby(['user_id']).agg('sum').reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:41.449729Z","iopub.execute_input":"2024-04-05T19:55:41.450031Z","iopub.status.idle":"2024-04-05T19:55:46.455115Z","shell.execute_reply.started":"2024-04-05T19:55:41.450004Z","shell.execute_reply":"2024-04-05T19:55:46.454261Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"negative_mcc_code_dumn_20000 = transactions[transactions['mcc_code'].isin(count_mcc_code20000)][['user_id', 'trans_negative', 'mcc_code']]\nnegative_mcc_code_dumn_20000 = negative_mcc_code_dumn_20000.pivot_table(values=\"trans_negative\",\n    index=\"user_id\",\n    columns=\"mcc_code\",\n    aggfunc='sum',\n    fill_value=0,)\nnegative_mcc_code_dumn_20000.columns = list(\n    map(lambda x: \"negative_mcc_code_sum_\"+str(x), negative_mcc_code_dumn_20000.columns))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:46.456138Z","iopub.execute_input":"2024-04-05T19:55:46.456425Z","iopub.status.idle":"2024-04-05T19:55:48.298558Z","shell.execute_reply.started":"2024-04-05T19:55:46.456400Z","shell.execute_reply":"2024-04-05T19:55:48.297461Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"positive_mcc_code_dumn_20000 = transactions[transactions['mcc_code'].isin(count_mcc_code20000)][['user_id', 'trans_positive', 'mcc_code']]\npositive_mcc_code_dumn_20000 = positive_mcc_code_dumn_20000.pivot_table(values=\"trans_positive\",\n    index=\"user_id\",\n    columns=\"mcc_code\",\n    aggfunc='sum',\n    fill_value=0,)\npositive_mcc_code_dumn_20000.columns = list(\n    map(lambda x: \"positive_mcc_code_sum_\"+str(x), positive_mcc_code_dumn_20000.columns))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:48.299779Z","iopub.execute_input":"2024-04-05T19:55:48.300065Z","iopub.status.idle":"2024-04-05T19:55:50.055663Z","shell.execute_reply.started":"2024-04-05T19:55:48.300040Z","shell.execute_reply":"2024-04-05T19:55:50.054611Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"count_mcc_code10000 = np.array(count_mcc_code[count_mcc_code['count']>=1000000].mcc_code)\nmcc_code_dumm10000 = transactions[transactions['mcc_code'].isin(count_mcc_code10000)][['user_id','mcc_code','trans_positive','trans_negative']]\nmcc_code_dumm10000 = mcc_code_dumm10000.groupby(['user_id']).agg(\n    {\n        'mcc_code': 'count',\n        'trans_positive' : 'sum',\n        'trans_negative' : 'sum'\n    }).reset_index().rename(columns={'mcc_code':'mcc_count_big', 'trans_positive':'trans_positive_big', 'trans_negative':'trans_negative_big'})","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:50.057123Z","iopub.execute_input":"2024-04-05T19:55:50.057453Z","iopub.status.idle":"2024-04-05T19:55:51.110316Z","shell.execute_reply.started":"2024-04-05T19:55:50.057425Z","shell.execute_reply":"2024-04-05T19:55:51.109320Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"count_mcc_code10000 = np.array(count_mcc_code[count_mcc_code['count']<=20000].mcc_code)\nmcc_code_dumm00001 = transactions[transactions['mcc_code'].isin(count_mcc_code10000)][['user_id','mcc_code','trans_positive','trans_negative']]\nmcc_code_dumm00001 = mcc_code_dumm00001.groupby(['user_id']).agg(\n    {\n        'mcc_code': 'count',\n        'trans_positive' : 'sum',\n        'trans_negative' : 'sum'        \n    }).reset_index().rename(columns={'mcc_code':'mcc_count_small', 'trans_positive':'trans_positive_small', 'trans_negative':'trans_negative_small'})","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:51.111602Z","iopub.execute_input":"2024-04-05T19:55:51.111957Z","iopub.status.idle":"2024-04-05T19:55:51.382623Z","shell.execute_reply.started":"2024-04-05T19:55:51.111924Z","shell.execute_reply":"2024-04-05T19:55:51.381856Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# 4.","metadata":{}},{"cell_type":"code","source":"percent_last_negative = clients[['user_id']].copy()\nfor x in [3, 30, 60, 90]:\n    prev = transactions[transactions['days_to_report'] > x + 100].groupby('user_id')['trans_negative'].agg(['sum']).\\\n    reset_index().rename({'sum': f'sum_transaction_before_{x}_days'}, axis=1)\n    last = transactions[transactions['days_to_report'] <= x + 100].groupby('user_id')['trans_negative'].agg(['sum']).\\\n    reset_index().rename({'sum': f'sum_transaction_last_{x}_days'}, axis=1)\n\n    percent_last_negative = percent_last_negative.merge(prev, how='left', on='user_id')\n    percent_last_negative = percent_last_negative.merge(last, how='left', on='user_id')\n    percent_last_negative[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n    percent_last_negative[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n    \n    percent_last_negative[f'negative_sum_percent_last_{x}'] = np.log((percent_last_negative[f'sum_transaction_last_{x}_days'] / \\\n    percent_last_negative[f'sum_transaction_before_{x}_days'])*100)\n    percent_last_negative[f'negative_sum_percent_last_{x}'] = percent_last_negative[f'negative_sum_percent_last_{x}'].replace(np.inf, 100)\n    percent_last_negative[f'negative_sum_percent_last_{x}'] = percent_last_negative[f'negative_sum_percent_last_{x}'].replace(-np.inf, -100)\n    percent_last_negative.drop(f'sum_transaction_last_{x}_days', inplace=True, axis=1)\n    percent_last_negative.drop(f'sum_transaction_before_{x}_days', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:51.383839Z","iopub.execute_input":"2024-04-05T19:55:51.384112Z","iopub.status.idle":"2024-04-05T19:55:57.787268Z","shell.execute_reply.started":"2024-04-05T19:55:51.384088Z","shell.execute_reply":"2024-04-05T19:55:57.786336Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3551169480.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3551169480.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/tmp/ipykernel_34/3551169480.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3551169480.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/tmp/ipykernel_34/3551169480.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3551169480.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/tmp/ipykernel_34/3551169480.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3551169480.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_negative[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"percent_last_positive = clients[['user_id']].copy()\nfor x in [3, 30, 60, 90]:\n    prev = transactions[transactions['days_to_report'] > x + 100].groupby('user_id')['trans_positive'].agg(['sum']).\\\n    reset_index().rename({'sum': f'sum_transaction_before_{x}_days'}, axis=1)\n    last = transactions[transactions['days_to_report'] <= x + 100].groupby('user_id')['trans_positive'].agg(['sum']).\\\n    reset_index().rename({'sum': f'sum_transaction_last_{x}_days'}, axis=1)\n\n    percent_last_positive = percent_last_positive.merge(prev, how='left', on='user_id')\n    percent_last_positive = percent_last_positive.merge(last, how='left', on='user_id')\n    percent_last_positive[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n    percent_last_positive[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n    \n    percent_last_positive[f'positive_sum_percent_last_{x}'] = np.log((percent_last_positive[f'sum_transaction_last_{x}_days'] / \\\n    percent_last_positive[f'sum_transaction_before_{x}_days'])*100)\n    percent_last_positive[f'positive_sum_percent_last_{x}'] = percent_last_positive[f'positive_sum_percent_last_{x}'].replace(np.inf, 100)\n    percent_last_positive[f'positive_sum_percent_last_{x}'] = percent_last_positive[f'positive_sum_percent_last_{x}'].replace(-np.inf, -100)\n    percent_last_positive.drop(f'sum_transaction_last_{x}_days', inplace=True, axis=1)\n    percent_last_positive.drop(f'sum_transaction_before_{x}_days', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:55:57.788339Z","iopub.execute_input":"2024-04-05T19:55:57.788598Z","iopub.status.idle":"2024-04-05T19:56:04.076147Z","shell.execute_reply.started":"2024-04-05T19:55:57.788575Z","shell.execute_reply":"2024-04-05T19:56:04.075016Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1014336589.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/1014336589.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/tmp/ipykernel_34/1014336589.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/1014336589.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/tmp/ipykernel_34/1014336589.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/1014336589.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/tmp/ipykernel_34/1014336589.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/1014336589.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last_positive[f'sum_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"percent_last = clients[['user_id']].copy()\nfor x in [3, 30, 60, 90]:\n    prev = transactions[transactions['days_to_report'] > x + 100].groupby('user_id')['report_dt'].agg(['count']).\\\n    reset_index().rename({'count': f'num_transaction_before_{x}_days'}, axis=1)\n    last = transactions[transactions['days_to_report'] <= x + 100].groupby('user_id')['report_dt'].agg(['count']).\\\n    reset_index().rename({'count': f'num_transaction_last_{x}_days'}, axis=1)\n\n    percent_last = percent_last.merge(prev, how='left', on='user_id')\n    percent_last = percent_last.merge(last, how='left', on='user_id')\n    percent_last[f'num_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n    percent_last[f'num_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n    \n    percent_last[f'percent_last_{x}'] = (percent_last[f'num_transaction_last_{x}_days'] / \\\n    percent_last[f'num_transaction_before_{x}_days'])*100\n    percent_last.drop(f'num_transaction_last_{x}_days', inplace=True, axis=1)\n    percent_last.drop(f'num_transaction_before_{x}_days', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:04.077898Z","iopub.execute_input":"2024-04-05T19:56:04.078243Z","iopub.status.idle":"2024-04-05T19:56:10.138479Z","shell.execute_reply.started":"2024-04-05T19:56:04.078212Z","shell.execute_reply":"2024-04-05T19:56:10.137356Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3304853712.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_last_{x}_days'].fillna(.000001, inplace=True)\n/tmp/ipykernel_34/3304853712.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  percent_last[f'num_transaction_before_{x}_days'].fillna(0.000001, inplace=True)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5.","metadata":{}},{"cell_type":"code","source":"transactions['m'] = (transactions['report_dt'].dt.year-transactions['transaction_dttm'].dt.year)*12+(transactions['report_dt'].dt.month-transactions['transaction_dttm'].dt.month)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:10.139999Z","iopub.execute_input":"2024-04-05T19:56:10.140421Z","iopub.status.idle":"2024-04-05T19:56:11.839951Z","shell.execute_reply.started":"2024-04-05T19:56:10.140383Z","shell.execute_reply":"2024-04-05T19:56:11.839176Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"msumm = transactions.pivot_table(values=\"trans_negative\",\n    index=\"user_id\",\n    columns=\"m\",\n    aggfunc='sum',\n    fill_value=0,)\nmsumm.columns = list( map(lambda x: \"msumm\"+str(x), msumm.columns ) )\nmsumm","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:11.841013Z","iopub.execute_input":"2024-04-05T19:56:11.841302Z","iopub.status.idle":"2024-04-05T19:56:13.003849Z","shell.execute_reply.started":"2024-04-05T19:56:11.841265Z","shell.execute_reply":"2024-04-05T19:56:13.002818Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"               msumm3         msumm4         msumm5         msumm6  \\\nuser_id                                                              \n3            0.000000       0.000000   15144.601562  153866.890625   \n9        13289.485764  104223.187939  109800.056656   54146.384140   \n13       16394.193359   27095.248047   27650.769531   76186.732422   \n37       32719.820328   41364.700729   67081.604048   53322.076138   \n41        8045.445801   17708.008820   30354.633301   17462.199585   \n...               ...            ...            ...            ...   \n562043       0.000000     142.056610       0.000000    2984.231926   \n562205   10452.779190    7546.495855    6601.707232    4821.073084   \n562312       0.000000    2644.634823    1362.274536    3165.544842   \n562721   20904.990967   12082.776123   27648.169678   64254.888449   \n562740   31250.922503   36796.173475   33804.052334   26213.265722   \n\n               msumm7        msumm8        msumm9  \nuser_id                                            \n3         3390.320969      0.000000      0.000000  \n9        18500.321304  12387.577271  11087.653740  \n13       33908.388672  53024.051758  19224.679688  \n37       69769.034760  50056.823341  28284.328693  \n41       18175.117676  16841.208984      0.000000  \n...               ...           ...           ...  \n562043   11080.026783  15374.940796      0.000000  \n562205    6082.155629   5607.360139   1349.243835  \n562312    3938.301605   4495.630554   2931.434910  \n562721   30059.568512  42680.736959    764.794891  \n562740   20043.419868  14351.860060    528.079102  \n\n[96000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>msumm3</th>\n      <th>msumm4</th>\n      <th>msumm5</th>\n      <th>msumm6</th>\n      <th>msumm7</th>\n      <th>msumm8</th>\n      <th>msumm9</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15144.601562</td>\n      <td>153866.890625</td>\n      <td>3390.320969</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13289.485764</td>\n      <td>104223.187939</td>\n      <td>109800.056656</td>\n      <td>54146.384140</td>\n      <td>18500.321304</td>\n      <td>12387.577271</td>\n      <td>11087.653740</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>16394.193359</td>\n      <td>27095.248047</td>\n      <td>27650.769531</td>\n      <td>76186.732422</td>\n      <td>33908.388672</td>\n      <td>53024.051758</td>\n      <td>19224.679688</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>32719.820328</td>\n      <td>41364.700729</td>\n      <td>67081.604048</td>\n      <td>53322.076138</td>\n      <td>69769.034760</td>\n      <td>50056.823341</td>\n      <td>28284.328693</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>8045.445801</td>\n      <td>17708.008820</td>\n      <td>30354.633301</td>\n      <td>17462.199585</td>\n      <td>18175.117676</td>\n      <td>16841.208984</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>562043</th>\n      <td>0.000000</td>\n      <td>142.056610</td>\n      <td>0.000000</td>\n      <td>2984.231926</td>\n      <td>11080.026783</td>\n      <td>15374.940796</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>562205</th>\n      <td>10452.779190</td>\n      <td>7546.495855</td>\n      <td>6601.707232</td>\n      <td>4821.073084</td>\n      <td>6082.155629</td>\n      <td>5607.360139</td>\n      <td>1349.243835</td>\n    </tr>\n    <tr>\n      <th>562312</th>\n      <td>0.000000</td>\n      <td>2644.634823</td>\n      <td>1362.274536</td>\n      <td>3165.544842</td>\n      <td>3938.301605</td>\n      <td>4495.630554</td>\n      <td>2931.434910</td>\n    </tr>\n    <tr>\n      <th>562721</th>\n      <td>20904.990967</td>\n      <td>12082.776123</td>\n      <td>27648.169678</td>\n      <td>64254.888449</td>\n      <td>30059.568512</td>\n      <td>42680.736959</td>\n      <td>764.794891</td>\n    </tr>\n    <tr>\n      <th>562740</th>\n      <td>31250.922503</td>\n      <td>36796.173475</td>\n      <td>33804.052334</td>\n      <td>26213.265722</td>\n      <td>20043.419868</td>\n      <td>14351.860060</td>\n      <td>528.079102</td>\n    </tr>\n  </tbody>\n</table>\n<p>96000 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clients = pd.read_csv('/kaggle/input/data-fusion-contest-2024-2/clients.csv')\ndf = clients.merge(\n    train, on=\"user_id\", how=\"left\").merge(\n    min_day_trans, on=\"user_id\", how=\"left\").merge(\n    max_day_trans, on=\"user_id\", how=\"left\").merge(\n    count_trans, on=\"user_id\", how=\"left\").merge(\n    nunique_days, on=\"user_id\", how=\"left\").merge(\n    trans_days_groups, on=\"user_id\", how=\"left\").merge(\n    trans_cur_groups, on=\"user_id\", how=\"left\").merge(\n    mcc_days_groups, on=\"user_id\", how=\"left\").merge(\n    mcc_code_dumm20000, on=\"user_id\", how=\"left\").merge(\n    negative_mcc_code_dumn_20000, on=\"user_id\", how=\"left\").merge(\n    positive_mcc_code_dumn_20000, on=\"user_id\", how=\"left\").merge(\n    mcc_code_dumm10000, on=\"user_id\", how=\"left\").merge(\n    mcc_code_dumm00001, on=\"user_id\", how=\"left\").merge(\n    percent_last, on=\"user_id\", how=\"left\").merge(\n    percent_last_negative, on=\"user_id\", how=\"left\").merge(\n    percent_last_positive, on=\"user_id\", how=\"left\").merge(\n    msumm, on=\"user_id\", how=\"left\")\ndf['pl_days_trans']=(df['max_day_trans']-df['min_day_trans'])/df['nunique_days']\ndf['pl_count_trans']=df['count_trans']/df['nunique_days']","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:13.005083Z","iopub.execute_input":"2024-04-05T19:56:13.005409Z","iopub.status.idle":"2024-04-05T19:56:14.700315Z","shell.execute_reply.started":"2024-04-05T19:56:13.005382Z","shell.execute_reply":"2024-04-05T19:56:14.699302Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df.replace({'employee_count_nm':{'ОТ 101 ДО 500':1,'БОЛЕЕ 1001':2,'ОТ 501 ДО 1000':3,'ДО 10':4,\n                                      'ОТ 11 ДО 50':5,'ОТ 51 ДО 100':6,'БОЛЕЕ 500':7,'ОТ 11 ДО 30':8,\n                                      'ОТ 31 ДО 50':9}}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:14.701516Z","iopub.execute_input":"2024-04-05T19:56:14.701808Z","iopub.status.idle":"2024-04-05T19:56:14.780377Z","shell.execute_reply.started":"2024-04-05T19:56:14.701782Z","shell.execute_reply":"2024-04-05T19:56:14.779449Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2153049573.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df.replace({'employee_count_nm':{'ОТ 101 ДО 500':1,'БОЛЕЕ 1001':2,'ОТ 501 ДО 1000':3,'ДО 10':4,\n","output_type":"stream"}]},{"cell_type":"code","source":"df['label'] = np.where(df['target']==0, -df['time'], df['time'])\ndf['time'] = df['time'].fillna(-1)\ndf['time'] = df['time'].astype(np.int32)\ndf['target'] = df['target'].fillna(-1)\ndf['target'] = df['target'].astype(np.int8)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:14.781387Z","iopub.execute_input":"2024-04-05T19:56:14.781660Z","iopub.status.idle":"2024-04-05T19:56:14.791057Z","shell.execute_reply.started":"2024-04-05T19:56:14.781631Z","shell.execute_reply":"2024-04-05T19:56:14.790326Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:14.792197Z","iopub.execute_input":"2024-04-05T19:56:14.792549Z","iopub.status.idle":"2024-04-05T19:56:14.817174Z","shell.execute_reply.started":"2024-04-05T19:56:14.792519Z","shell.execute_reply":"2024-04-05T19:56:14.816345Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   user_id  report  employee_count_nm  bankemplstatus  customer_age  target  \\\n0        3       2                1.0               0             3       0   \n1        9       1                2.0               0             3      -1   \n2       13       6                3.0               0             2       0   \n3       37       5                2.0               0             2       0   \n4       41       1                1.0               0             2       0   \n\n   time  min_day_trans  max_day_trans  count_trans  ...        msumm3  \\\n0    77            108            214           11  ...      0.000000   \n1    -1            102            283           90  ...  13289.485764   \n2    86            114            282           22  ...  16394.193359   \n3    89            104            283          315  ...  32719.820328   \n4    57            103            256           16  ...   8045.445801   \n\n          msumm4         msumm5         msumm6        msumm7        msumm8  \\\n0       0.000000   15144.601562  153866.890625   3390.320969      0.000000   \n1  104223.187939  109800.056656   54146.384140  18500.321304  12387.577271   \n2   27095.248047   27650.769531   76186.732422  33908.388672  53024.051758   \n3   41364.700729   67081.604048   53322.076138  69769.034760  50056.823341   \n4   17708.008820   30354.633301   17462.199585  18175.117676  16841.208984   \n\n         msumm9  pl_days_trans  pl_count_trans  label  \n0      0.000000      13.250000        1.375000  -77.0  \n1  11087.653740       3.351852        1.666667    NaN  \n2  19224.679688       9.333333        1.222222  -86.0  \n3  28284.328693       1.376923        2.423077  -89.0  \n4      0.000000      12.750000        1.333333  -57.0  \n\n[5 rows x 248 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>report</th>\n      <th>employee_count_nm</th>\n      <th>bankemplstatus</th>\n      <th>customer_age</th>\n      <th>target</th>\n      <th>time</th>\n      <th>min_day_trans</th>\n      <th>max_day_trans</th>\n      <th>count_trans</th>\n      <th>...</th>\n      <th>msumm3</th>\n      <th>msumm4</th>\n      <th>msumm5</th>\n      <th>msumm6</th>\n      <th>msumm7</th>\n      <th>msumm8</th>\n      <th>msumm9</th>\n      <th>pl_days_trans</th>\n      <th>pl_count_trans</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>77</td>\n      <td>108</td>\n      <td>214</td>\n      <td>11</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15144.601562</td>\n      <td>153866.890625</td>\n      <td>3390.320969</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>13.250000</td>\n      <td>1.375000</td>\n      <td>-77.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>102</td>\n      <td>283</td>\n      <td>90</td>\n      <td>...</td>\n      <td>13289.485764</td>\n      <td>104223.187939</td>\n      <td>109800.056656</td>\n      <td>54146.384140</td>\n      <td>18500.321304</td>\n      <td>12387.577271</td>\n      <td>11087.653740</td>\n      <td>3.351852</td>\n      <td>1.666667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>6</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>86</td>\n      <td>114</td>\n      <td>282</td>\n      <td>22</td>\n      <td>...</td>\n      <td>16394.193359</td>\n      <td>27095.248047</td>\n      <td>27650.769531</td>\n      <td>76186.732422</td>\n      <td>33908.388672</td>\n      <td>53024.051758</td>\n      <td>19224.679688</td>\n      <td>9.333333</td>\n      <td>1.222222</td>\n      <td>-86.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>5</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>89</td>\n      <td>104</td>\n      <td>283</td>\n      <td>315</td>\n      <td>...</td>\n      <td>32719.820328</td>\n      <td>41364.700729</td>\n      <td>67081.604048</td>\n      <td>53322.076138</td>\n      <td>69769.034760</td>\n      <td>50056.823341</td>\n      <td>28284.328693</td>\n      <td>1.376923</td>\n      <td>2.423077</td>\n      <td>-89.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>57</td>\n      <td>103</td>\n      <td>256</td>\n      <td>16</td>\n      <td>...</td>\n      <td>8045.445801</td>\n      <td>17708.008820</td>\n      <td>30354.633301</td>\n      <td>17462.199585</td>\n      <td>18175.117676</td>\n      <td>16841.208984</td>\n      <td>0.000000</td>\n      <td>12.750000</td>\n      <td>1.333333</td>\n      <td>-57.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 248 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_columns = [col for col in df.columns if col not in ['user_id', 'report_dt', 'label', 'target', \n                                                          'time', 'count_trans']]","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:14.818026Z","iopub.execute_input":"2024-04-05T19:56:14.818254Z","iopub.status.idle":"2024-04-05T19:56:14.822475Z","shell.execute_reply.started":"2024-04-05T19:56:14.818227Z","shell.execute_reply":"2024-04-05T19:56:14.821573Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df_train = df[(df['time']!=-1)].copy()\nX = df_train[train_columns]\ny = df_train[['label','time','target']]\ny_label = df_train[['label']]","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:14.827002Z","iopub.execute_input":"2024-04-05T19:56:14.827243Z","iopub.status.idle":"2024-04-05T19:56:15.053105Z","shell.execute_reply.started":"2024-04-05T19:56:14.827223Z","shell.execute_reply":"2024-04-05T19:56:15.052240Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def fit_xgboost(trial, train, val):\n    X_train_cur, y_train_cur = train\n    X_val_cur, y_val_cur = val\n\n    param = {\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.01),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 16),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 6, 20),\n        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.8),\n        \"gamma\": trial.suggest_int(\"gamma\", 1, 5),\n        \"reg_lambda\": trial.suggest_float(\"reg_lambda\",1.0, 3.0),\n        \"reg_alpha\": trial.suggest_float(\"reg_alpha\",1.0, 3.0),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.75, 1.0),\n        \"max_bin\": trial.suggest_categorical(\"max_bin\", [128, 256, 512])\n    }\n\n    model = xgb.XGBRegressor(objective=\"survival:cox\",\n                             random_state=458,\n                             tree_method = \"hist\",\n                             n_estimators=10000,\n                             device=\"cuda\",\n                             **param)\n    \n    model.fit(X_train_cur,\n              y_train_cur[['label']],\n              early_stopping_rounds=500, \n              eval_set=[(X_val_cur, y_val_cur[['label']])],\n              verbose=1000)\n\n    y_pred = model.predict(X_val_cur)\n    \n    return model, y_pred","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:20.739052Z","iopub.execute_input":"2024-04-05T11:57:20.744258Z","iopub.status.idle":"2024-04-05T11:57:20.812812Z","shell.execute_reply.started":"2024-04-05T11:57:20.744211Z","shell.execute_reply":"2024-04-05T11:57:20.798906Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"def objective(trial, return_models=False):\n    \n    n_splits=5\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    scores, models = [], []\n    \n    for train_index, val_index in skf.split(X, y_label):\n        train_data = X.iloc[train_index], y.iloc[train_index]\n        valid_data = X.iloc[val_index], y.iloc[val_index]\n        \n        model, y_pred = fit_xgboost(trial, train_data, valid_data)\n        \n        scores.append(concordance_index(valid_data[1].time, -y_pred, valid_data[1].target))\n        models.append(model)\n\n    result = np.mean(scores)\n\n    if return_models:\n        return result, models\n    else:\n        return result","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:49:21.080592Z","iopub.execute_input":"2024-04-05T11:49:21.080969Z","iopub.status.idle":"2024-04-05T11:49:21.088970Z","shell.execute_reply.started":"2024-04-05T11:49:21.080938Z","shell.execute_reply":"2024-04-05T11:49:21.087965Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective,\n               n_trials=300,\n               n_jobs = -1,\n               show_progress_bar=True,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:52:44.866195Z","iopub.execute_input":"2024-04-05T19:52:44.866556Z","iopub.status.idle":"2024-04-05T19:52:44.880609Z","shell.execute_reply.started":"2024-04-05T19:52:44.866529Z","shell.execute_reply":"2024-04-05T19:52:44.879726Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.0010119044289866191,\n 'max_depth': 11,\n 'min_child_weight': 6,\n 'colsample_bylevel': 0.0964029721202083,\n 'gamma': 1,\n 'reg_lambda': 1.05415902329896,\n 'reg_alpha': 1.2690885998724977,\n 'subsample': 0.7696892304354142,\n 'max_bin': 512}"},"metadata":{}},{"name":"stdout","text":"[5000]\tvalidation_0-cox-nloglik:8.74261\n[6000]\tvalidation_0-cox-nloglik:8.74087\n[5000]\tvalidation_0-cox-nloglik:8.65179\n[7000]\tvalidation_0-cox-nloglik:8.74006\n[6000]\tvalidation_0-cox-nloglik:8.65034\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rates = np.linspace(0.005, 0.001, iters).tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits=5\nscores = []\nmodels = []\n\nlearning_rates = np.linspace(0.0035, 0.0015, 8000).tolist()\nscheduler = xgb.callback.LearningRateScheduler(learning_rates)\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=33)\n\nfor train_index, val_index in skf.split(X, y_label):\n    \n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    \n    dtrain = xgb.DMatrix(X_train,\n                         label=y_train[['label']],\n                         nthread=-1,\n                         enable_categorical=True,)\n\n    dtest = xgb.DMatrix(X_val,\n                        y_val[['label']],\n                        nthread=-1,\n                        enable_categorical=True)\n\n    params = {\n        \"objective\": \"survival:cox\",\n        \"random_state\": 458,\n        \"reg_lambda\": 1.5,\n        \"reg_alpha\":1.4,\n        \"subsample\": .8,\n        \"colsample_bytree\": .3,\n        \"gamma\": 3,\n        \"min_child_weight\": 16,\n        \"max_depth\": 6, #max_depth=8\n        \"learning_rate\": 0.003,#learning_rate=0.003,\n        \"tree_method\": \"hist\",\n        \"max_bin\": 512,\n        #\"n_estimators\": 8000,#n_estimators=5000\n        \"device\": \"cuda\"\n    }\n    \n    model = xgb.train(params,\n                    dtrain=dtrain,\n                    early_stopping_rounds=500,\n                    evals=[(dtrain, 'dtrain'), (dtest, 'dtest')],\n                    #callbacks=[scheduler],\n                    num_boost_round=8000,\n                    verbose_eval=1000,\n                    )\n    \n    models.append(model)\n\n    predictions_xgb = model.predict(dtest)\n    scores.append(concordance_index(y_val.time, -predictions_xgb, y_val.target))\n\nnp.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:50:31.019558Z","iopub.execute_input":"2024-04-05T20:50:31.020570Z","iopub.status.idle":"2024-04-05T20:55:54.665917Z","shell.execute_reply.started":"2024-04-05T20:50:31.020524Z","shell.execute_reply":"2024-04-05T20:55:54.664908Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"[0]\tdtrain-cox-nloglik:10.65341\tdtest-cox-nloglik:9.26792\n[1000]\tdtrain-cox-nloglik:9.93765\tdtest-cox-nloglik:8.73830\n[2000]\tdtrain-cox-nloglik:9.79039\tdtest-cox-nloglik:8.69916\n[3000]\tdtrain-cox-nloglik:9.69219\tdtest-cox-nloglik:8.68811\n[4000]\tdtrain-cox-nloglik:9.60631\tdtest-cox-nloglik:8.68443\n[5000]\tdtrain-cox-nloglik:9.53557\tdtest-cox-nloglik:8.68359\n[5936]\tdtrain-cox-nloglik:9.47784\tdtest-cox-nloglik:8.68382\n[0]\tdtrain-cox-nloglik:10.65400\tdtest-cox-nloglik:9.26703\n[1000]\tdtrain-cox-nloglik:9.94280\tdtest-cox-nloglik:8.72852\n[2000]\tdtrain-cox-nloglik:9.79211\tdtest-cox-nloglik:8.68843\n[3000]\tdtrain-cox-nloglik:9.69203\tdtest-cox-nloglik:8.67985\n[4000]\tdtrain-cox-nloglik:9.60742\tdtest-cox-nloglik:8.67779\n[5000]\tdtrain-cox-nloglik:9.53439\tdtest-cox-nloglik:8.67734\n[5836]\tdtrain-cox-nloglik:9.48269\tdtest-cox-nloglik:8.67805\n[0]\tdtrain-cox-nloglik:10.65326\tdtest-cox-nloglik:9.26765\n[1000]\tdtrain-cox-nloglik:9.94722\tdtest-cox-nloglik:8.72233\n[2000]\tdtrain-cox-nloglik:9.80046\tdtest-cox-nloglik:8.68260\n[3000]\tdtrain-cox-nloglik:9.70381\tdtest-cox-nloglik:8.67539\n[4000]\tdtrain-cox-nloglik:9.62029\tdtest-cox-nloglik:8.67324\n[5000]\tdtrain-cox-nloglik:9.54559\tdtest-cox-nloglik:8.67252\n[5367]\tdtrain-cox-nloglik:9.52318\tdtest-cox-nloglik:8.67309\n[0]\tdtrain-cox-nloglik:10.65334\tdtest-cox-nloglik:9.26702\n[1000]\tdtrain-cox-nloglik:9.94693\tdtest-cox-nloglik:8.71568\n[2000]\tdtrain-cox-nloglik:9.80580\tdtest-cox-nloglik:8.67725\n[3000]\tdtrain-cox-nloglik:9.71189\tdtest-cox-nloglik:8.66741\n[4000]\tdtrain-cox-nloglik:9.63046\tdtest-cox-nloglik:8.66371\n[5000]\tdtrain-cox-nloglik:9.55896\tdtest-cox-nloglik:8.66265\n[5529]\tdtrain-cox-nloglik:9.52557\tdtest-cox-nloglik:8.66280\n[0]\tdtrain-cox-nloglik:10.65314\tdtest-cox-nloglik:9.26768\n[1000]\tdtrain-cox-nloglik:9.94061\tdtest-cox-nloglik:8.75590\n[2000]\tdtrain-cox-nloglik:9.79749\tdtest-cox-nloglik:8.71870\n[3000]\tdtrain-cox-nloglik:9.70017\tdtest-cox-nloglik:8.70939\n[4000]\tdtrain-cox-nloglik:9.61606\tdtest-cox-nloglik:8.70610\n[5000]\tdtrain-cox-nloglik:9.54331\tdtest-cox-nloglik:8.70522\n[5074]\tdtrain-cox-nloglik:9.53815\tdtest-cox-nloglik:8.70532\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"0.7763006319524732"},"metadata":{}}]},{"cell_type":"code","source":"n_splits=5\nscores = []\nmodels = []\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=33)\n\nfor train_index, val_index in skf.split(X, y_label):\n    \n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n\n    model = xgb.XGBRegressor(objective=\"survival:cox\",\n                             random_state=458,\n                             reg_lambda=1.5,\n                             reg_alpha=1.4,\n                             subsample=.8,\n                             colsample_bytree=.3,\n                             gamma=3,\n                             min_child_weight=16,\n                             max_depth=8, #max_depth=6\n                             learning_rate=0.003,#learning_rate=0.005,\n                             tree_method = \"hist\",\n                             n_estimators=8000,#n_estimators=5000\n                             device=\"cuda\")\n    model.fit(X_train,\n              y_train[['label']],\n              early_stopping_rounds=500, #early_stopping_rounds=400\n              eval_set=[(X_val, y_val[['label']])],\n              verbose=500,\n              )\n    \n    models.append(model)\n\n    predictions_xgb = model.predict(X_val)\n    scores.append(concordance_index(y_val.time, -predictions_xgb, y_val.target))\n\nnp.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:56:15.054294Z","iopub.execute_input":"2024-04-05T19:56:15.054589Z","iopub.status.idle":"2024-04-05T20:00:09.812157Z","shell.execute_reply.started":"2024-04-05T19:56:15.054553Z","shell.execute_reply":"2024-04-05T20:00:09.811203Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-cox-nloglik:9.26806\n[500]\tvalidation_0-cox-nloglik:8.80042\n[1000]\tvalidation_0-cox-nloglik:8.72356\n[1500]\tvalidation_0-cox-nloglik:8.69810\n[2000]\tvalidation_0-cox-nloglik:8.68763\n[2500]\tvalidation_0-cox-nloglik:8.68259\n[3000]\tvalidation_0-cox-nloglik:8.68074\n[3500]\tvalidation_0-cox-nloglik:8.67973\n[4000]\tvalidation_0-cox-nloglik:8.67937\n[4500]\tvalidation_0-cox-nloglik:8.67890\n[4879]\tvalidation_0-cox-nloglik:8.67930\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [19:57:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-cox-nloglik:9.26695\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[500]\tvalidation_0-cox-nloglik:8.78936\n[1000]\tvalidation_0-cox-nloglik:8.71470\n[1500]\tvalidation_0-cox-nloglik:8.69071\n[2000]\tvalidation_0-cox-nloglik:8.68026\n[2500]\tvalidation_0-cox-nloglik:8.67600\n[3000]\tvalidation_0-cox-nloglik:8.67423\n[3500]\tvalidation_0-cox-nloglik:8.67364\n[4000]\tvalidation_0-cox-nloglik:8.67389\n[4226]\tvalidation_0-cox-nloglik:8.67407\n[0]\tvalidation_0-cox-nloglik:9.26754\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[500]\tvalidation_0-cox-nloglik:8.78996\n[1000]\tvalidation_0-cox-nloglik:8.71122\n[1500]\tvalidation_0-cox-nloglik:8.68604\n[2000]\tvalidation_0-cox-nloglik:8.67631\n[2500]\tvalidation_0-cox-nloglik:8.67308\n[3000]\tvalidation_0-cox-nloglik:8.67225\n[3461]\tvalidation_0-cox-nloglik:8.67238\n[0]\tvalidation_0-cox-nloglik:9.26691\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[500]\tvalidation_0-cox-nloglik:8.78157\n[1000]\tvalidation_0-cox-nloglik:8.70213\n[1500]\tvalidation_0-cox-nloglik:8.67745\n[2000]\tvalidation_0-cox-nloglik:8.66759\n[2500]\tvalidation_0-cox-nloglik:8.66293\n[3000]\tvalidation_0-cox-nloglik:8.66045\n[3500]\tvalidation_0-cox-nloglik:8.65943\n[4000]\tvalidation_0-cox-nloglik:8.65899\n[4500]\tvalidation_0-cox-nloglik:8.65898\n[4806]\tvalidation_0-cox-nloglik:8.65934\n[0]\tvalidation_0-cox-nloglik:9.26762\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[500]\tvalidation_0-cox-nloglik:8.81788\n[1000]\tvalidation_0-cox-nloglik:8.74208\n[1500]\tvalidation_0-cox-nloglik:8.71776\n[2000]\tvalidation_0-cox-nloglik:8.70889\n[2500]\tvalidation_0-cox-nloglik:8.70391\n[3000]\tvalidation_0-cox-nloglik:8.70274\n[3500]\tvalidation_0-cox-nloglik:8.70090\n[3998]\tvalidation_0-cox-nloglik:8.70137\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.7768874993890824"},"metadata":{}}]},{"cell_type":"code","source":"for i, model in enumerate(models):\n    file_name = f\"xgb_{i}.pkl\"\n    pickle.dump(model, open(file_name, \"wb\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:23:28.199307Z","iopub.execute_input":"2024-04-05T10:23:28.200900Z","iopub.status.idle":"2024-04-05T10:23:28.532221Z","shell.execute_reply.started":"2024-04-05T10:23:28.200839Z","shell.execute_reply":"2024-04-05T10:23:28.530888Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df_imp = pd.DataFrame(list(X_train), models[0].feature_importances_)\ndf_imp.columns = [\"Feature_Names\"]\ndf_imp[\"Importances\"] = df_imp.index\ndf_imp = df_imp.sort_values(by = \"Importances\", ascending = False)\ndf_imp.index = np.arange(0,len(df_imp))\ndf_imp.head(50)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:24:09.417038Z","iopub.execute_input":"2024-04-05T11:24:09.417974Z","iopub.status.idle":"2024-04-05T11:24:09.444631Z","shell.execute_reply.started":"2024-04-05T11:24:09.417939Z","shell.execute_reply":"2024-04-05T11:24:09.443632Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"                          Feature_Names  Importances\n0                          mcc_count_51     0.062791\n1              positive_mcc_code_sum_51     0.061640\n2                          customer_age     0.033481\n3                     employee_count_nm     0.031282\n4     cur_groups_count_trans_negative_0     0.015299\n5                                msumm3     0.010870\n6                         min_day_trans     0.010809\n7       cur_groups_min_trans_negative_0     0.010523\n8     days_groups_min_trans_positive_10     0.008301\n9                  trans_negative_small     0.008252\n10            negative_mcc_code_sum_155     0.008052\n11                               msumm4     0.007962\n12                        mcc_count_155     0.007921\n13      cur_groups_max_trans_positive_0     0.007743\n14              positive_mcc_code_sum_0     0.007624\n15                      percent_last_30     0.007555\n16             positive_mcc_code_sum_12     0.007523\n17      cur_groups_max_trans_positive_1     0.007200\n18  days_groups_count_trans_positive_10     0.007037\n19    days_groups_max_trans_positive_10     0.006993\n20                          mcc_count_0     0.006914\n21    cur_groups_count_trans_positive_1     0.006872\n22      cur_groups_sum_trans_negative_1     0.006756\n23                       pl_count_trans     0.006661\n24                       percent_last_3     0.006553\n25     days_groups_min_trans_positive_5     0.006117\n26      cur_groups_sum_trans_negative_0     0.006011\n27             negative_mcc_code_sum_28     0.006002\n28              negative_mcc_code_sum_8     0.005971\n29      cur_groups_sum_trans_positive_0     0.005922\n30             negative_mcc_code_sum_15     0.005906\n31    cur_groups_count_trans_positive_0     0.005881\n32     days_groups_max_trans_positive_5     0.005876\n33                      percent_last_60     0.005757\n34                         mcc_count_28     0.005733\n35                               report     0.005677\n36      cur_groups_sum_trans_positive_1     0.005414\n37                        max_day_trans     0.005355\n38      cur_groups_min_trans_positive_0     0.005335\n39                        pl_days_trans     0.005206\n40                         mcc_count_15     0.005180\n41    cur_groups_count_trans_negative_1     0.005116\n42                 trans_positive_small     0.005108\n43                         mcc_count_12     0.005034\n44      cur_groups_max_trans_negative_1     0.004849\n45          negative_sum_percent_last_3     0.004758\n46    days_groups_sum_trans_positive_10     0.004686\n47   days_groups_count_trans_positive_5     0.004615\n48          positive_sum_percent_last_3     0.004585\n49                         mcc_count_26     0.004528","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature_Names</th>\n      <th>Importances</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mcc_count_51</td>\n      <td>0.062791</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>positive_mcc_code_sum_51</td>\n      <td>0.061640</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>customer_age</td>\n      <td>0.033481</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>employee_count_nm</td>\n      <td>0.031282</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cur_groups_count_trans_negative_0</td>\n      <td>0.015299</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>msumm3</td>\n      <td>0.010870</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>min_day_trans</td>\n      <td>0.010809</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>cur_groups_min_trans_negative_0</td>\n      <td>0.010523</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>days_groups_min_trans_positive_10</td>\n      <td>0.008301</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>trans_negative_small</td>\n      <td>0.008252</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>negative_mcc_code_sum_155</td>\n      <td>0.008052</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>msumm4</td>\n      <td>0.007962</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mcc_count_155</td>\n      <td>0.007921</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cur_groups_max_trans_positive_0</td>\n      <td>0.007743</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>positive_mcc_code_sum_0</td>\n      <td>0.007624</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>percent_last_30</td>\n      <td>0.007555</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>positive_mcc_code_sum_12</td>\n      <td>0.007523</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>cur_groups_max_trans_positive_1</td>\n      <td>0.007200</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>days_groups_count_trans_positive_10</td>\n      <td>0.007037</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>days_groups_max_trans_positive_10</td>\n      <td>0.006993</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>mcc_count_0</td>\n      <td>0.006914</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>cur_groups_count_trans_positive_1</td>\n      <td>0.006872</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>cur_groups_sum_trans_negative_1</td>\n      <td>0.006756</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>pl_count_trans</td>\n      <td>0.006661</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>percent_last_3</td>\n      <td>0.006553</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>days_groups_min_trans_positive_5</td>\n      <td>0.006117</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>cur_groups_sum_trans_negative_0</td>\n      <td>0.006011</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>negative_mcc_code_sum_28</td>\n      <td>0.006002</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>negative_mcc_code_sum_8</td>\n      <td>0.005971</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>cur_groups_sum_trans_positive_0</td>\n      <td>0.005922</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>negative_mcc_code_sum_15</td>\n      <td>0.005906</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>cur_groups_count_trans_positive_0</td>\n      <td>0.005881</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>days_groups_max_trans_positive_5</td>\n      <td>0.005876</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>percent_last_60</td>\n      <td>0.005757</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>mcc_count_28</td>\n      <td>0.005733</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>report</td>\n      <td>0.005677</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>cur_groups_sum_trans_positive_1</td>\n      <td>0.005414</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>max_day_trans</td>\n      <td>0.005355</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>cur_groups_min_trans_positive_0</td>\n      <td>0.005335</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>pl_days_trans</td>\n      <td>0.005206</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>mcc_count_15</td>\n      <td>0.005180</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>cur_groups_count_trans_negative_1</td>\n      <td>0.005116</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>trans_positive_small</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>mcc_count_12</td>\n      <td>0.005034</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>cur_groups_max_trans_negative_1</td>\n      <td>0.004849</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>negative_sum_percent_last_3</td>\n      <td>0.004758</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>days_groups_sum_trans_positive_10</td>\n      <td>0.004686</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>days_groups_count_trans_positive_5</td>\n      <td>0.004615</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>positive_sum_percent_last_3</td>\n      <td>0.004585</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>mcc_count_26</td>\n      <td>0.004528</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"d_test = xgb.DMatrix(df[df['time']==-1][train_columns].copy(),\n                    nthread=-1,\n                    enable_categorical=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:41:56.190849Z","iopub.execute_input":"2024-04-05T20:41:56.191183Z","iopub.status.idle":"2024-04-05T20:41:56.481009Z","shell.execute_reply.started":"2024-04-05T20:41:56.191156Z","shell.execute_reply":"2024-04-05T20:41:56.480017Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"predictions = models[0].predict(d_test)\nfor i in range(1, len(models)):\n    predictions += models[i].predict(d_test)\npredictions /= 5\nsubmit = df[df['time']==-1][['user_id']].copy()\nsubmit['predict'] = predictions\nsubmit.to_csv(f'submission_xgboost_6.csv',index=False)\nsubmit","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:55:54.667653Z","iopub.execute_input":"2024-04-05T20:55:54.668383Z","iopub.status.idle":"2024-04-05T20:56:01.279049Z","shell.execute_reply.started":"2024-04-05T20:55:54.668345Z","shell.execute_reply":"2024-04-05T20:56:01.278158Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"       user_id   predict\n1            9  0.303870\n9           61  0.259679\n10          62  0.920720\n17          80  0.114155\n20          88  3.522721\n...        ...       ...\n95988   561362  0.988217\n95990   561419  1.465799\n95993   561895  1.022656\n95994   561908  2.505330\n95996   562205  1.252680\n\n[32000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0.303870</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>61</td>\n      <td>0.259679</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>62</td>\n      <td>0.920720</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>80</td>\n      <td>0.114155</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>88</td>\n      <td>3.522721</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95988</th>\n      <td>561362</td>\n      <td>0.988217</td>\n    </tr>\n    <tr>\n      <th>95990</th>\n      <td>561419</td>\n      <td>1.465799</td>\n    </tr>\n    <tr>\n      <th>95993</th>\n      <td>561895</td>\n      <td>1.022656</td>\n    </tr>\n    <tr>\n      <th>95994</th>\n      <td>561908</td>\n      <td>2.505330</td>\n    </tr>\n    <tr>\n      <th>95996</th>\n      <td>562205</td>\n      <td>1.252680</td>\n    </tr>\n  </tbody>\n</table>\n<p>32000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}